{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pad0910-cnn-transfer-learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpx-dVEvYC29",
        "outputId": "d1c72068-725c-4c50-d63e-ae60d231547a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-09 10:28:18--  https://md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com/4drtyfjtfy-1.zip\n",
            "Resolving md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com (md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com)... 52.218.44.26\n",
            "Connecting to md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com (md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com)|52.218.44.26|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 95592747 (91M) [application/octet-stream]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]  91.16M  25.6MB/s    in 3.6s    \n",
            "\n",
            "2022-01-09 10:28:22 (25.6 MB/s) - ‘data.zip’ saved [95592747/95592747]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O data.zip \"https://md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com/4drtyfjtfy-1.zip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPuM1xduYbRz",
        "outputId": "75947f3a-340d-406b-9055-2fc9b4dc2b14"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "  inflating: dataset2.zip            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dataset2.zip"
      ],
      "metadata": {
        "id": "38tgOwPaYixc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil, glob"
      ],
      "metadata": {
        "id": "J0AwyKnTYwfg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "types = [ (\"Cloudy\",\"cloud*.*\"), (\"Rainy\",\"rain*.*\"), (\"Shiny\",\"shin*.*\"), (\"Sunrise\",\"sunrise*.*\")  ]\n",
        "\n",
        "shutil.rmtree(\"dataset\")\n",
        "for folder_name, file_mask in types:\n",
        "  files = sorted(glob.glob(\"dataset2/\"+file_mask))\n",
        "  os.makedirs(f\"dataset/Train/{folder_name}\")\n",
        "  os.makedirs(f\"dataset/Test/{folder_name}\")\n",
        "\n",
        "  train_qnty = int(0.8*len(files))\n",
        "\n",
        "  [shutil.copy(item, f\"dataset/Train/{folder_name}\") for item in files[:train_qnty] ]\n",
        "  [shutil.copy(item, f\"dataset/Test/{folder_name}\") for item in files[train_qnty:] ]\n",
        "  print(folder_name, file_mask, len(files))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7zgzDOdZVoi",
        "outputId": "cecfe4f5-5b6b-4cd7-a7ca-ef6c4bee83dc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloudy cloud*.* 300\n",
            "Rainy rain*.* 215\n",
            "Shiny shin*.* 253\n",
            "Sunrise sunrise*.* 357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O cup.jpeg \"https://lh5.googleusercontent.com/sTDIn5BK6czLJsB9u-m-VcLma4a6IbJ6rKL0NC3Vp8XESJuAoc5detOT9wtNobOX2CvCX4Qtel21vr7R3Jnv13MrbNIy-yhb-4z6H08wIthMXhce8mjglvufpLOzgx0ftFbvGphn\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jF8oEBJFcDTB",
        "outputId": "9b6d274e-1651-4192-a4af-2f1e5bfd2b59"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-09 10:46:41--  https://lh5.googleusercontent.com/sTDIn5BK6czLJsB9u-m-VcLma4a6IbJ6rKL0NC3Vp8XESJuAoc5detOT9wtNobOX2CvCX4Qtel21vr7R3Jnv13MrbNIy-yhb-4z6H08wIthMXhce8mjglvufpLOzgx0ftFbvGphn\n",
            "Resolving lh5.googleusercontent.com (lh5.googleusercontent.com)... 173.194.210.132, 2607:f8b0:400c:c0f::84\n",
            "Connecting to lh5.googleusercontent.com (lh5.googleusercontent.com)|173.194.210.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 38944 (38K) [image/jpeg]\n",
            "Saving to: ‘cup.jpeg’\n",
            "\n",
            "\rcup.jpeg              0%[                    ]       0  --.-KB/s               \rcup.jpeg            100%[===================>]  38.03K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-01-09 10:46:41 (95.4 MB/s) - ‘cup.jpeg’ saved [38944/38944]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.models import Model"
      ],
      "metadata": {
        "id": "FSkBq9Cwcoug"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# łądowanie grafiki\n",
        "img = load_img(\"cup.jpeg\", target_size=(224,224) )\n",
        "\n",
        "# konwersja na tablice NumPy\n",
        "img_arr = img_to_array(img)\n",
        "\n",
        "arr = np.expand_dims(img_arr, axis=0)\n",
        "# konwersja na potrzeby sieci\n",
        "arr = preprocess_input(arr)"
      ],
      "metadata": {
        "id": "rxqpActudafn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG16()\n",
        "prediction = model.predict(arr)"
      ],
      "metadata": {
        "id": "K2Zt-E7Udx_I"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decode_predictions(prediction)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj9wdLpYeZYo",
        "outputId": "1508e7d6-58a0-4070-8e78-5ae4a8c16dbe"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('n03063599', 'coffee_mug', 0.25186822),\n",
              " ('n07930864', 'cup', 0.17223488),\n",
              " ('n04263257', 'soup_bowl', 0.16073191),\n",
              " ('n07920052', 'espresso', 0.14333373),\n",
              " ('n03733805', 'measuring_cup', 0.08206768)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "-aDuU2uLfJgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning Transfer z sieci VGG16\n",
        "model = VGG16(include_top=False, input_shape=(224,224,3))\n",
        "for layer in model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "hidden = Flatten()(model.output)\n",
        "outputs = Dense(4, activation=\"softmax\")(hidden)\n",
        "\n",
        "# tworzenie nowej sieci na podstawie instniejącej\n",
        "model = Model(inputs=model.input, outputs=outputs)\n",
        "\n",
        "# zobacz strukture\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCDy6ENGgUfi",
        "outputId": "158fd693-c0fe-45d9-9af4-97198dad1716"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 100356    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,815,044\n",
            "Trainable params: 100,356\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# kompilacja\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Z-kee8r7mao6"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "0MuLm0FkoX98"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Augemntacja danych dla sieci\n",
        "\n",
        "train_datagen = ImageDataGenerator(    \n",
        "    rotation_range = 40, zoom_range = 0.2,\n",
        "    shear_range = 0.2, horizontal_flip = True, vertical_flip = True,\n",
        "    width_shift_range = 0.2,\n",
        "    rescale = 1/255\n",
        ")\n",
        "train_generator = train_datagen.flow_from_directory(directory=\"dataset/Train\", target_size=(224,224), class_mode=\"categorical\")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale = 1/255\n",
        ")\n",
        "test_generator = test_datagen.flow_from_directory(directory=\"dataset/Test\", target_size=(224,224), class_mode=\"categorical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nqh8AjWGop1U",
        "outputId": "8d922b50-2c45-4b63-fbca-f7988a7fe010"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 899 images belonging to 4 classes.\n",
            "Found 226 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(train_generator, validation_data=test_generator, epochs=5)"
      ],
      "metadata": {
        "id": "ojqYv1CmpSmf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}